{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emaddar/NLP-NER/blob/Models/Spacy_en_core_web_sm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NdRitT8329p"
      },
      "source": [
        "**Building Custom Named Entity Recognition Model Using Spacy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh_gXGxU2bwE"
      },
      "source": [
        "https://newscatcherapi.com/blog/train-custom-named-entity-recognition-ner-model-with-spacy-v3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFOiNNeP0giN",
        "outputId": "54866626-8c13-496a-d488-b117ce873ce7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n"
          ]
        }
      ],
      "source": [
        "import spacy   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enIOTr8y6hf9",
        "outputId": "60b57886-1298-49df-df8a-d841a10e16d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-16 08:38:53.803471: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-16 08:38:53.803644: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-16 08:38:53.803682: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-16 08:38:56.585852: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.4.1/en_core_web_lg-3.4.1-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-lg==3.4.1) (3.4.4)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.22.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (63.4.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.4.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.25.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.1.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.0.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (6.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (3.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.10.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.65.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (1.26.15)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-lg==3.4.1) (2.1.2)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.4.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n"
          ]
        }
      ],
      "source": [
        "# !python -m spacy download en_core_web_sm\n",
        "!python -m spacy download en_core_web_lg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGlQY8Ro2hw6",
        "outputId": "d8d8a881-f23b-49d9-e1f1-82676bc705ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x7f6d29d51430>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp = spacy.load(\"en_core_web_lg\")\n",
        "nlp "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGingzbmvgnL"
      },
      "outputs": [],
      "source": [
        "doc = nlp(\"Donad Trump was President of USA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFPOI7gY-ha4",
        "outputId": "b5177348-0e91-4344-ba8d-bf6161f07d3f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Donad Trump was President of USA"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2U0jLPSqx8CT",
        "outputId": "24b742a3-d58f-4082-96b3-f34e06319d05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWrodKDk-jwc",
        "outputId": "4ece91e5-4ce1-49e3-8f62-fc55602c9a62"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "spacy.tokens.doc.Doc"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7WS3fl38D_0",
        "outputId": "fdf602f3-6db8-43f3-fef8-254f9a103a69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Donad Trump, USA)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc.ents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AovSOSmKvlz9",
        "outputId": "2f8d3d7a-4cdb-4e0b-ce92-34cbac8673a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(Donad Trump, spacy.tokens.span.Span)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc.ents[0], type(doc.ents[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "5ou7-MtW8gXW",
        "outputId": "2b514997-037b-4904-ac80-17248026d1da"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Donad Trump\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " was President of \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    USA\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              "</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QIeRdwg21l6"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "# https://www.kaggle.com/datasets/dataturks/resume-entities-for-ner?resource=download\n",
        "data = [json.loads(line) for line in open('/content/drive/MyDrive/NER_in_Resumes.json', 'r')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSBtqpmn9a3N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_json (r'/content/drive/MyDrive/NER_in_Resumes.json',lines=True)\n",
        "df.to_csv (r'dataframe.csv', index = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZXJoIgJa9e3d",
        "outputId": "62ccf0d2-61f8-4bf9-8ae6-6f0f6a7bfc77"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-33df97b7-0ae7-4b24-ad07-6aa5e7c3f5fb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>annotation</th>\n",
              "      <th>extras</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abhishek Jha\\nApplication Development Associat...</td>\n",
              "      <td>[{'label': ['Skills'], 'points': [{'start': 12...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Afreen Jamadar\\nActive member of IIIT Committe...</td>\n",
              "      <td>[{'label': ['Email Address'], 'points': [{'sta...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Akhil Yadav Polemaina\\nHyderabad, Telangana - ...</td>\n",
              "      <td>[{'label': ['Skills'], 'points': [{'start': 37...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Alok Khandai\\nOperational Analyst (SQL DBA) En...</td>\n",
              "      <td>[{'label': ['Skills'], 'points': [{'start': 80...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...</td>\n",
              "      <td>[{'label': ['Degree'], 'points': [{'start': 20...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>Mansi Thanki\\nStudent\\n\\nJamnagar, Gujarat - E...</td>\n",
              "      <td>[{'label': ['College Name'], 'points': [{'star...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>Anil Kumar\\nMicrosoft Azure (Basic Management)...</td>\n",
              "      <td>[{'label': ['Location'], 'points': [{'start': ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>Siddharth Choudhary\\nMicrosoft Office Suite - ...</td>\n",
              "      <td>[{'label': ['Skills'], 'points': [{'start': 78...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>Valarmathi Dhandapani\\nInvestment Banking Oper...</td>\n",
              "      <td>[{'label': ['Skills'], 'points': [{'start': 92...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>Pradeep Kumar\\nSecurity Analyst in Infosys - C...</td>\n",
              "      <td>[{'label': ['Skills'], 'points': [{'start': 58...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>220 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33df97b7-0ae7-4b24-ad07-6aa5e7c3f5fb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-33df97b7-0ae7-4b24-ad07-6aa5e7c3f5fb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-33df97b7-0ae7-4b24-ad07-6aa5e7c3f5fb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               content  \\\n",
              "0    Abhishek Jha\\nApplication Development Associat...   \n",
              "1    Afreen Jamadar\\nActive member of IIIT Committe...   \n",
              "2    Akhil Yadav Polemaina\\nHyderabad, Telangana - ...   \n",
              "3    Alok Khandai\\nOperational Analyst (SQL DBA) En...   \n",
              "4    Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...   \n",
              "..                                                 ...   \n",
              "215  Mansi Thanki\\nStudent\\n\\nJamnagar, Gujarat - E...   \n",
              "216  Anil Kumar\\nMicrosoft Azure (Basic Management)...   \n",
              "217  Siddharth Choudhary\\nMicrosoft Office Suite - ...   \n",
              "218  Valarmathi Dhandapani\\nInvestment Banking Oper...   \n",
              "219  Pradeep Kumar\\nSecurity Analyst in Infosys - C...   \n",
              "\n",
              "                                            annotation  extras  \n",
              "0    [{'label': ['Skills'], 'points': [{'start': 12...     NaN  \n",
              "1    [{'label': ['Email Address'], 'points': [{'sta...     NaN  \n",
              "2    [{'label': ['Skills'], 'points': [{'start': 37...     NaN  \n",
              "3    [{'label': ['Skills'], 'points': [{'start': 80...     NaN  \n",
              "4    [{'label': ['Degree'], 'points': [{'start': 20...     NaN  \n",
              "..                                                 ...     ...  \n",
              "215  [{'label': ['College Name'], 'points': [{'star...     NaN  \n",
              "216  [{'label': ['Location'], 'points': [{'start': ...     NaN  \n",
              "217  [{'label': ['Skills'], 'points': [{'start': 78...     NaN  \n",
              "218  [{'label': ['Skills'], 'points': [{'start': 92...     NaN  \n",
              "219  [{'label': ['Skills'], 'points': [{'start': 58...     NaN  \n",
              "\n",
              "[220 rows x 3 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtksxtBq3y1i"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/NER_in_Resumes.json'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "armtwzwtuawW"
      },
      "outputs": [],
      "source": [
        "# import logging\n",
        "import json\n",
        "import re\n",
        "\n",
        "# JSON formatting functions\n",
        "def convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n",
        "    training_data = []\n",
        "    lines=[]\n",
        "    with open(dataturks_JSON_FilePath, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        data = json.loads(line)\n",
        "        text = data['content'].replace(\"\\n\", \" \")\n",
        "        entities = []\n",
        "        data_annotations = data['annotation']\n",
        "        if data_annotations is not None:\n",
        "            for annotation in data_annotations:\n",
        "                #only a single point in text annotation.\n",
        "                point = annotation['points'][0]\n",
        "                labels = annotation['label']\n",
        "                # handle both list of labels or a single label.\n",
        "                if not isinstance(labels, list):\n",
        "                    labels = [labels]\n",
        "\n",
        "                for label in labels:\n",
        "                    point_start = point['start']\n",
        "                    point_end = point['end']\n",
        "                    point_text = point['text']\n",
        "\n",
        "                    lstrip_diff = len(point_text) - len(point_text.lstrip())\n",
        "                    rstrip_diff = len(point_text) - len(point_text.rstrip())\n",
        "                    if lstrip_diff != 0:\n",
        "                        point_start = point_start + lstrip_diff\n",
        "                    if rstrip_diff != 0:\n",
        "                        point_end = point_end - rstrip_diff\n",
        "                    entities.append((point_start, point_end + 1 , label))\n",
        "        training_data.append((text, {\"entities\" : entities}))\n",
        "    return training_data\n",
        "\n",
        "def trim_entity_spans(data: list) -> list:\n",
        "    \"\"\"Removes leading and trailing white spaces from entity spans.\n",
        "\n",
        "    Args:\n",
        "        data (list): The data to be cleaned in spaCy JSON format.\n",
        "\n",
        "    Returns:\n",
        "        list: The cleaned data.\n",
        "    \"\"\"\n",
        "    invalid_span_tokens = re.compile(r'\\s')\n",
        "\n",
        "    cleaned_data = []\n",
        "    for text, annotations in data:\n",
        "        entities = annotations['entities']\n",
        "        valid_entities = []\n",
        "        for start, end, label in entities:\n",
        "            valid_start = start\n",
        "            valid_end = end\n",
        "            while valid_start < len(text) and invalid_span_tokens.match(\n",
        "                    text[valid_start]):\n",
        "                valid_start += 1\n",
        "            while valid_end > 1 and invalid_span_tokens.match(\n",
        "                    text[valid_end - 1]):\n",
        "                valid_end -= 1\n",
        "            valid_entities.append([valid_start, valid_end, label])\n",
        "        cleaned_data.append([text, {'entities': valid_entities}])\n",
        "    return cleaned_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xv1zceiBubdn",
        "outputId": "7cf1fcf5-69d9-4dd2-bcd0-8a410a6db14c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"Abhishek Jha Application Development Associate - Accenture  Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a  • To work for an organization which provides me the opportunity to improve my skills and knowledge for my individual and company's growth in best possible ways.  Willing to relocate to: Bangalore, Karnataka  WORK EXPERIENCE  Application Development Associate  Accenture -  November 2017 to Present  Role: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries for the Bot which will be triggered based on given input. Also, Training the bot for different possible utterances (Both positive and negative), which will be given as input by the user.  EDUCATION  B.E in Information science and engineering  B.v.b college of engineering and technology -  Hubli, Karnataka  August 2013 to June 2017  12th in Mathematics  Woodbine modern school  April 2011 to March 2013  10th  Kendriya Vidyalaya  April 2001 to March 2011  SKILLS  C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year), Database Management System (Less than 1 year), Java (Less than 1 year)  ADDITIONAL INFORMATION  Technical Skills  https://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN   • Programming language: C, C++, Java • Oracle PeopleSoft • Internet Of Things • Machine Learning • Database Management System • Computer Networks • Operating System worked on: Linux, Windows, Mac  Non - Technical Skills  • Honest and Hard-Working • Tolerant and Flexible to Different Situations • Polite and Calm • Team-Player\",\n",
              " {'entities': [[1296, 1622, 'Skills'],\n",
              "   [993, 1154, 'Skills'],\n",
              "   [939, 957, 'College Name'],\n",
              "   [883, 905, 'College Name'],\n",
              "   [856, 860, 'Graduation Year'],\n",
              "   [771, 814, 'College Name'],\n",
              "   [727, 769, 'Designation'],\n",
              "   [407, 416, 'Companies worked at'],\n",
              "   [372, 405, 'Designation'],\n",
              "   [95, 145, 'Email Address'],\n",
              "   [60, 69, 'Location'],\n",
              "   [49, 58, 'Companies worked at'],\n",
              "   [13, 46, 'Designation'],\n",
              "   [0, 12, 'Name']]}]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data = trim_entity_spans(convert_dataturks_to_spacy(\"/content/drive/MyDrive/NER_in_Resumes.json\"))\n",
        "training_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "MfAGFErMug0Z",
        "outputId": "1a5c61d1-a897-41f1-89e8-8690c37fa578"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Abhishek Jha Application Development Associate - Accenture  Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a  • To work for an organization which provides me the opportunity to improve my skills and knowledge for my individual and company's growth in best possible ways.  Willing to relocate to: Bangalore, Karnataka  WORK EXPERIENCE  Application Development Associate  Accenture -  November 2017 to Present  Role: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries for the Bot which will be triggered based on given input. Also, Training the bot for different possible utterances (Both positive and negative), which will be given as input by the user.  EDUCATION  B.E in Information science and engineering  B.v.b college of engineering and technology -  Hubli, Karnataka  August 2013 to June 2017  12th in Mathematics  Woodbine modern school  April 2011 to March 2013  10th  Kendriya Vidyalaya  April 2001 to March 2011  SKILLS  C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year), Database Management System (Less than 1 year), Java (Less than 1 year)  ADDITIONAL INFORMATION  Technical Skills  https://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN   • Programming language: C, C++, Java • Oracle PeopleSoft • Internet Of Things • Machine Learning • Database Management System • Computer Networks • Operating System worked on: Linux, Windows, Mac  Non - Technical Skills  • Honest and Hard-Working • Tolerant and Flexible to Different Situations • Polite and Calm • Team-Player\""
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data[0][0]  # training_data[0]['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq39FL0Kuy3j",
        "outputId": "79a0eba7-8477-4955-c447-7a2b090a7e8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[1296, 1622, 'Skills'],\n",
              " [993, 1154, 'Skills'],\n",
              " [939, 957, 'College Name'],\n",
              " [883, 905, 'College Name'],\n",
              " [856, 860, 'Graduation Year'],\n",
              " [771, 814, 'College Name'],\n",
              " [727, 769, 'Designation'],\n",
              " [407, 416, 'Companies worked at'],\n",
              " [372, 405, 'Designation'],\n",
              " [95, 145, 'Email Address'],\n",
              " [60, 69, 'Location'],\n",
              " [49, 58, 'Companies worked at'],\n",
              " [13, 46, 'Designation'],\n",
              " [0, 12, 'Name']]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data[0][1]['entities'] # training_data[0]['entities']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kzIYcapou6pl",
        "outputId": "7ec63f78-b016-4827-ab90-9ab59cd4ab24"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2017'"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data[0][0][856 : 860]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXHAakaYvSDI"
      },
      "outputs": [],
      "source": [
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "\n",
        "nlp = spacy.blank(\"en\") # load a new spacy model\n",
        "doc_bin = DocBin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoTOzlLXvyfe",
        "outputId": "127ee343-c220-4382-bcab-0c30e10f843f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|▌         | 13/220 [00:00<00:03, 58.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|█▎        | 30/220 [00:00<00:02, 68.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 49/220 [00:00<00:02, 79.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|███       | 67/220 [00:00<00:01, 77.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 34%|███▍      | 75/220 [00:01<00:01, 75.74it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 38%|███▊      | 83/220 [00:01<00:02, 65.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▎     | 96/220 [00:01<00:02, 49.55it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 110/220 [00:01<00:02, 49.10it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 57%|█████▋    | 125/220 [00:02<00:01, 53.61it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 70%|███████   | 155/220 [00:02<00:00, 76.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 75%|███████▍  | 164/220 [00:02<00:00, 72.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r 78%|███████▊  | 172/220 [00:02<00:00, 58.29it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 86%|████████▋ | 190/220 [00:03<00:00, 68.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 95%|█████████▍| 208/220 [00:03<00:00, 66.58it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n",
            "Skipping entity\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 220/220 [00:03<00:00, 62.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity\n"
          ]
        }
      ],
      "source": [
        "from spacy.util import filter_spans\n",
        "\n",
        "for training_example  in tqdm(training_data): \n",
        "    text = training_example[0]\n",
        "    labels = training_example[1]['entities']\n",
        "    doc = nlp.make_doc(text) \n",
        "    ents = []\n",
        "    for start, end, label in labels:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
        "        if span is None:\n",
        "            print(\"Skipping entity\")\n",
        "        else:\n",
        "            ents.append(span)\n",
        "    filtered_ents = filter_spans(ents)\n",
        "    doc.ents = filtered_ents \n",
        "    doc_bin.add(doc)\n",
        "\n",
        "doc_bin.to_disk(\"train.spacy\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz2ptN71ydhZ"
      },
      "outputs": [],
      "source": [
        "def clean_entities(training_data):\n",
        "    \n",
        "    clean_data = []\n",
        "    for text, annotation in training_data:\n",
        "        \n",
        "        entities = annotation.get('entities')\n",
        "        entities_copy = entities.copy()\n",
        "        \n",
        "        # append entity only if it is longer than its overlapping entity\n",
        "        i = 0\n",
        "        for entity in entities_copy:\n",
        "            j = 0\n",
        "            for overlapping_entity in entities_copy:\n",
        "                # Skip self\n",
        "                if i != j:\n",
        "                    e_start, e_end, oe_start, oe_end = entity[0], entity[1], overlapping_entity[0], overlapping_entity[1]\n",
        "                    # Delete any entity that overlaps, keep if longer\n",
        "                    if ((e_start >= oe_start and e_start <= oe_end) \\\n",
        "                    or (e_end <= oe_end and e_end >= oe_start)) \\\n",
        "                    and ((e_end - e_start) <= (oe_end - oe_start)):\n",
        "                        entities.remove(entity)\n",
        "                j += 1\n",
        "            i += 1\n",
        "        clean_data.append((text, {'entities': entities}))\n",
        "                \n",
        "    return clean_data\n",
        "\n",
        "training_data = clean_entities(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnsRvm3t4OYJ"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "def remove_whitespace(entities):\n",
        "    result = []\n",
        "    for text, annotation in entities:\n",
        "        new_annotation = copy.deepcopy(annotation)\n",
        "        for entity in new_annotation.get('entities', []):\n",
        "            start, end, label = entity\n",
        "            entity_text = text[start:end].strip()\n",
        "            new_entity = [start, start+len(entity_text), label]\n",
        "            new_annotation['entities'].remove(entity)\n",
        "            new_annotation['entities'].append(new_entity)\n",
        "        result.append((text.strip(), new_annotation))\n",
        "    return result\n",
        "  \n",
        "training_data = remove_whitespace(training_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUizOUW_7K1Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrY-NmOh7KyY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHMKrpyrwEiv",
        "outputId": "b2cc3545-f6aa-4b87-b3f2-ff84e8498ff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-15 15:26:17.281597: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-15 15:26:17.281761: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-15 15:26:17.281796: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-15 15:26:19.661593: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRjT7wJDwLL7",
        "outputId": "bd14e1c6-11aa-4dd4-99fe-4e226a9b748f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-15 15:26:44.420584: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-15 15:26:44.420935: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-15 15:26:44.420970: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-15 15:26:46.748808: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[38;5;4mℹ Saving to output directory: .\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2023-03-15 15:26:48,240] [INFO] Set up nlp object from config\n",
            "[2023-03-15 15:26:48,261] [INFO] Pipeline: ['tok2vec', 'ner']\n",
            "[2023-03-15 15:26:48,268] [INFO] Created vocabulary\n",
            "[2023-03-15 15:26:52,133] [INFO] Added vectors: en_core_web_lg\n",
            "[2023-03-15 15:26:56,701] [INFO] Finished initializing nlp object\n",
            "[2023-03-15 15:27:12,330] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
            "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  ------------  --------  ------  ------  ------  ------\n",
            "  0       0          0.00     87.24    0.00    0.00    0.00    0.00\n",
            "\u001b[38;5;3m⚠ Aborting and saving the final best model. Encountered exception:\n",
            "ValueError(\"[E024] Could not find an optimal move to supervise the parser.\n",
            "Usually, this means that the model can't be updated in a way that's valid and\n",
            "satisfies the correct annotations specified in the GoldParse. For example, are\n",
            "all labels added to the model? If you're training a named entity recognizer,\n",
            "also make sure that none of your annotated entity spans have leading or trailing\n",
            "whitespace or punctuation. You can also use the `debug data` command to validate\n",
            "your JSON-formatted training data. For details, run:\\npython -m spacy debug data\n",
            "--help\")\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/spacy/cli/_util.py\", line 71, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/click/core.py\", line 1130, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/typer/core.py\", line 778, in main\n",
            "    return _main(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/typer/core.py\", line 216, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/click/core.py\", line 1657, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/click/core.py\", line 1404, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/click/core.py\", line 760, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/typer/main.py\", line 683, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/spacy/cli/train.py\", line 45, in train_cli\n",
            "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/spacy/cli/train.py\", line 75, in train\n",
            "    train_nlp(nlp, output_path, use_gpu=use_gpu, stdout=sys.stdout, stderr=sys.stderr)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/spacy/training/loop.py\", line 122, in train\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/spacy/training/loop.py\", line 105, in train\n",
            "    for batch, info, is_best_checkpoint in training_step_iterator:\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/spacy/training/loop.py\", line 203, in train_while_improving\n",
            "    nlp.update(\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/spacy/language.py\", line 1170, in update\n",
            "    proc.update(examples, sgd=None, losses=losses, **component_cfg[name])  # type: ignore\n",
            "  File \"spacy/pipeline/transition_parser.pyx\", line 397, in spacy.pipeline.transition_parser.Parser.update\n",
            "  File \"spacy/pipeline/transition_parser.pyx\", line 653, in spacy.pipeline.transition_parser.Parser._init_gold_batch\n",
            "  File \"spacy/pipeline/_parser_internals/transition_system.pyx\", line 132, in spacy.pipeline._parser_internals.transition_system.TransitionSystem.get_oracle_sequence_from_state\n",
            "ValueError: [E024] Could not find an optimal move to supervise the parser. Usually, this means that the model can't be updated in a way that's valid and satisfies the correct annotations specified in the GoldParse. For example, are all labels added to the model? If you're training a named entity recognizer, also make sure that none of your annotated entity spans have leading or trailing whitespace or punctuation. You can also use the `debug data` command to validate your JSON-formatted training data. For details, run:\n",
            "python -m spacy debug data --help\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy train config.cfg --output ./ --paths.train ./train.spacy --paths.dev ./train.spacy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VfQAsPVw8uD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqQMO5RxyOgh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iGoNW4n4Dzc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
